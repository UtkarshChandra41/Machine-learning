{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cab0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a715cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model =Sequential ([\n",
    "    Dense(units =16, input_shape=(1,), activation= 'relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a16dda1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">642</span> (2.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m642\u001b[0m (2.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">642</span> (2.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m642\u001b[0m (2.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fb4ec",
   "metadata": {},
   "source": [
    " model:\n",
    "\n",
    "* `units`\n",
    "* `input_shape`\n",
    "* `activation='relu'` and `activation='softmax'`\n",
    "* And how we decide the number of units per layer (e.g., 16, 32, 2)\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Model Summary:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `input_shape=(1,)`\n",
    "\n",
    "* This tells the model what the **shape of each input sample** is.\n",
    "* `input_shape=(1,)` means: each sample is a **single scalar value** (like a column vector).\n",
    "* If you had, say, 5 features per sample, you'd use `input_shape=(5,)`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `units=16` / `32` / `2`\n",
    "\n",
    "* `units` defines how many **neurons** (also called nodes) are in that layer.\n",
    "* Each neuron receives input from the previous layer and outputs one number.\n",
    "* You can think of it as the **dimensionality** of the output of that layer.\n",
    "\n",
    "#### So:\n",
    "\n",
    "* `units=16`: this layer has 16 neurons.\n",
    "* `units=32`: this layer has 32 neurons.\n",
    "* `units=2`: final output layer has 2 neurons — useful for **binary classification** with **softmax**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 `activation='relu'` and `'softmax'`\n",
    "\n",
    "* Activation functions introduce **non-linearity** into the model. Without them, the network would behave like a linear model, no matter how deep it is.\n",
    "\n",
    "#### Common ones:\n",
    "\n",
    "* **ReLU (Rectified Linear Unit)**: `relu(x) = max(0, x)`\n",
    "\n",
    "  * Used in hidden layers\n",
    "  * Efficient and helps with gradient flow\n",
    "* **Softmax**: Converts output to **probabilities** that sum to 1.\n",
    "\n",
    "  * Used in the final layer for **multi-class classification** (or binary classification with 2 output units)\n",
    "  * Each value shows how likely the input is to belong to each class.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 How to Decide the Units (16 → 32 → 2)\n",
    "\n",
    "There’s **no single rule**, but here are some guidelines:\n",
    "\n",
    "#### 🔹 Hidden Layers (16 and 32):\n",
    "\n",
    "* These are called **dense (fully connected) hidden layers**.\n",
    "* 16 → 32 is a common pattern of increasing capacity.\n",
    "* You choose this based on:\n",
    "\n",
    "  * Size/complexity of your input data\n",
    "  * How nonlinear the mapping is\n",
    "  * Trial and error + cross-validation\n",
    "  * Rule of thumb: Start small and increase if underfitting\n",
    "\n",
    "#### 🔹 Output Layer (2 with softmax):\n",
    "\n",
    "* For **binary classification** using `softmax`, we use **2 output units**:\n",
    "\n",
    "  * `[prob_class_0, prob_class_1]`\n",
    "* For **multi-class (e.g., 3 classes)**, use 3 units.\n",
    "* If you’re doing binary classification with a single neuron, you can use:\n",
    "\n",
    "  ```python\n",
    "  Dense(units=1, activation='sigmoid')\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Visual Summary:\n",
    "\n",
    "```\n",
    "Input (1 feature)\n",
    "   ↓\n",
    "Dense (16 units, ReLU)\n",
    "   ↓\n",
    "Dense (32 units, ReLU)\n",
    "   ↓\n",
    "Dense (2 units, Softmax) → Outputs: [P(class_0), P(class_1)]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 TL;DR:\n",
    "\n",
    "| Term          | Meaning                                                                               |\n",
    "| ------------- | ------------------------------------------------------------------------------------- |\n",
    "| `units`       | Number of neurons in the layer                                                        |\n",
    "| `input_shape` | Shape of input sample (not batch!)                                                    |\n",
    "| `relu`        | Activation function for hidden layers (fast, simple)                                  |\n",
    "| `softmax`     | Turns outputs into probabilities (used in last layer for classification)              |\n",
    "| `16 → 32 → 2` | Arbitrary starting choice based on intuition, trial-and-error, and problem complexity |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fbebb0",
   "metadata": {},
   "source": [
    "Understanding **features** and **samples** is fundamental in machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "### What is a **Feature** and what is a **Sample**?\n",
    "\n",
    "* A **feature** is an individual measurable property or characteristic of the data.\n",
    "* A **sample** (also called an observation or data point) is **one instance** of your data that contains a set of features.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Example 1: **1 Feature per Sample**\n",
    "\n",
    "Imagine you're predicting house prices based **only on the size of the house** (in square feet).\n",
    "\n",
    "* Each house (sample) is described by **one feature**: size.\n",
    "* So your dataset might look like this:\n",
    "\n",
    "| House Size (sq ft) |\n",
    "| ------------------ |\n",
    "| 1200               |\n",
    "| 1500               |\n",
    "| 900                |\n",
    "| 2000               |\n",
    "\n",
    "Here:\n",
    "\n",
    "* Each **row** is a **sample** (one house).\n",
    "* Each **column** is a **feature** (house size).\n",
    "\n",
    "**Input shape** in this case: `(1,)` — one feature.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Example 2: **5 Features per Sample**\n",
    "\n",
    "Now imagine you want to predict house prices based on **5 features**:\n",
    "\n",
    "1. Size (sq ft)\n",
    "2. Number of bedrooms\n",
    "3. Number of bathrooms\n",
    "4. Distance to city center (miles)\n",
    "5. Age of the house (years)\n",
    "\n",
    "Your dataset might look like this:\n",
    "\n",
    "| Size | Bedrooms | Bathrooms | Distance | Age |\n",
    "| ---- | -------- | --------- | -------- | --- |\n",
    "| 1200 | 3        | 2         | 5        | 10  |\n",
    "| 1500 | 4        | 3         | 3        | 5   |\n",
    "| 900  | 2        | 1         | 7        | 20  |\n",
    "| 2000 | 5        | 4         | 2        | 2   |\n",
    "\n",
    "Here:\n",
    "\n",
    "* Each row is a **sample** (one house).\n",
    "* Each row has **5 features** describing it.\n",
    "\n",
    "**Input shape** in this case: `(5,)` — 5 features per sample.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "\n",
    "| Term               | Meaning                        | Example                        |\n",
    "| ------------------ | ------------------------------ | ------------------------------ |\n",
    "| Sample             | One data point / observation   | One house                      |\n",
    "| Feature            | One characteristic of a sample | House size, number of bedrooms |\n",
    "| Input shape `(1,)` | Each sample has 1 feature      | `[1200]` (just size)           |\n",
    "| Input shape `(5,)` | Each sample has 5 features     | `[1200, 3, 2, 5, 10]`          |\n",
    "\n",
    "---\n",
    "**imp**\n",
    "If you’re feeding this data to a neural network, your input layer’s shape needs to match the number of features per sample.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3233461",
   "metadata": {},
   "source": [
    "Training ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0164cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']   # metrics should be a list, even if just one metric\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae88ab57",
   "metadata": {},
   "source": [
    "Your `model.compile` line is almost correct but there’s a small fix needed for the **metrics** argument.\n",
    "\n",
    "---\n",
    "\n",
    "### What you wrote:\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Correct version:\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']   # metrics should be a list, even if just one metric\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "* **optimizer**: `Adam` is a popular, efficient optimizer.\n",
    "* **learning\\_rate**: 0.0001 is a small learning rate — good for fine tuning.\n",
    "* **loss**: `'sparse_categorical_crossentropy'` is used for multi-class classification where labels are integers (not one-hot encoded).\n",
    "* **metrics**: Should be a **list** of metrics, so wrap `'accuracy'` in square brackets `['accuracy']`.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
